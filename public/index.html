<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Real-time Speech Transcription with Summary</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            margin: 0;
            padding: 0;
            max-width: 100%;
            overflow-x: hidden;
            display: flex;
            flex-direction: column;
            align-items: center;
        }

        h1 {
            color: #333;
            font-size: 24px;
            text-align: center;
            margin: 20px 0;
        }

        .container {
            width: 90%;
            max-width: 600px;
            margin: 0 auto;
            padding: 10px;
            box-sizing: border-box;
        }

        button {
            margin: 5px 0;
            padding: 10px;
            font-size: 16px;
            width: 100%;
            box-sizing: border-box;
        }

        #transcript {
            border: 1px solid #ccc;
            padding: 10px;
            margin-top: 20px;
            height: 150px;
            overflow-y: auto;
            background-color: #f9f9f9;
            box-sizing: border-box;
            width: 100%;
        }

        .summary {
            background-color: #e0f7fa;
            padding: 10px;
            margin-top: 20px;
            border: 1px solid #00acc1;
            box-sizing: border-box;
            width: 100%;
        }

        .interim {
            color: gray;
        }

        label, select {
            width: 100%;
            display: block;
            margin-top: 10px;
            margin-bottom: 10px;
            font-size: 16px;
            box-sizing: border-box;
        }

        select {
            padding: 10px;
            border: 1px solid #ccc;
            border-radius: 4px;
            background-color: #fff;
        }

        @media (min-width: 600px) {
            button {
                width: auto;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>Real-time Speech Transcription with Summary</h1>
        <label for="language">Select Language:</label>
        <select id="language">
            <option value="en-US">English (US)</option>
            <option value="vi-VN">Vietnamese (VN)</option>
        </select>
        <label for="scale">Select the scale of the conversation:</label>
        <select id="scale">
            <option value="Meeting">Meeting</option>
            <option value="Lecture">Lecture</option>
            <option value="Interview">Interview</option>
            <option value="Conversation">Normal conversation</option>
            <option value="Presentation">Presentation</option>
        
        </select>
        <button id="start-button">Start</button>
        <button id="stop-button">Stop</button>
        <button id="summarize-button">Summarize</button>
        <div id="transcript"></div>
        <div id="summary" class="summary"></div>
    </div>

    <script>
        const startButton = document.getElementById('start-button');
        const stopButton = document.getElementById('stop-button');
        const summarizeButton = document.getElementById('summarize-button');
        const transcriptDiv = document.getElementById('transcript');
        const summaryDiv = document.getElementById('summary');
        const languageSelect = document.getElementById('language');
        const scaleSelect = document.getElementById('scale');
        
        const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
        const recognition = new SpeechRecognition();
        
        recognition.continuous = true;
        recognition.interimResults = true;

        let finalTranscript = '';

        recognition.onresult = (event) => {
            let interimTranscript = '';
            
            for (let i = event.resultIndex; i < event.results.length; i++) {
                const transcript = event.results[i][0].transcript;
                if (event.results[i].isFinal) {
                    finalTranscript += transcript + ' ';
                } else {
                    interimTranscript += transcript;
                }
            }
            transcriptDiv.innerHTML = `<p>${finalTranscript}</p><p class="interim">${interimTranscript}</p>`;
        };

        startButton.addEventListener('click', () => {
            recognition.lang = languageSelect.value;
            startAudioProcessing();
            recognition.start();
        });
        
        stopButton.addEventListener('click', () => {
            recognition.stop();
        });

        summarizeButton.addEventListener('click', async () => {
            try {
                const summary = await getSummary(finalTranscript);
                summaryDiv.innerHTML = `<h2>Summary</h2><p>${summary}</p>`;
            } catch (error) {
                console.error('Error getting summary:', error);
                summaryDiv.innerHTML = `<p style="color:red;">Error getting summary. Please try again.</p>`;
            }
        });

        async function getSummary(text) {
            const response = await fetch('https://conversation-summarizer-2.vercel.app/summarize', {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json'
                },
                body: JSON.stringify({ text })
            });

            if (!response.ok) {
                throw new Error('Error summarizing text');
            }

            const data = await response.json();
            return data.summary;
        }

        async function startAudioProcessing() {
            const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
            const audioContext = new (window.AudioContext || window.webkitAudioContext)();
            const source = audioContext.createMediaStreamSource(stream);
            
            // Create gain node to control volume
            const gainNode = audioContext.createGain();
            if (scaleSelect.value === "Meeting") gainNode.gain.value = 1.8;
            else if (scaleSelect.value === "Lecture") gainNode.gain.value = 2.5;
            else if (scaleSelect.value === "Interview") gainNode.gain.value = 1.2;
            else if (scaleSelect.value === "Conversation") gainNode.gain.value = 1.8;
            else if (scaleSelect.value === "Presentation") gainNode.gain.value = 2.0; // Increase the volume (default is 1.0)

            // Create biquad filter node for noise reduction
            const biquadFilter = audioContext.createBiquadFilter();
            biquadFilter.type = 'lowpass';
            biquadFilter.frequency.value = 1000; // Adjust this value to filter out high-frequency noise

            // Create a dummy destination to prevent audio output
            const dummyDestination = audioContext.createMediaStreamDestination();

            // Connect the nodes: source -> biquadFilter -> gainNode -> dummyDestination
            source.connect(biquadFilter);
            biquadFilter.connect(gainNode);
            gainNode.connect(dummyDestination);

            // Use a ScriptProcessorNode to capture the audio data and feed it to SpeechRecognition
            const scriptProcessor = audioContext.createScriptProcessor(2048, 1, 1);
            gainNode.connect(scriptProcessor);

            scriptProcessor.onaudioprocess = function(audioProcessingEvent) {
                const inputBuffer = audioProcessingEvent.inputBuffer;
                const outputBuffer = audioProcessingEvent.outputBuffer;

                for (let channel = 0; channel < outputBuffer.numberOfChannels; channel++) {
                    const inputData = inputBuffer.getChannelData(channel);
                    const outputData = outputBuffer.getChannelData(channel);

                    for (let sample = 0; sample < inputBuffer.length; sample++) {
                        outputData[sample] = inputData[sample];
                    }
                }
            };
        }
    </script>
</body>
</html>
